# **SARA Engine 商用化・高精度化ロードマップ**

## **フェーズ 1: 基盤の堅牢化 (完了)**

「動くもの」から「壊れない・運用できるもの」への脱皮。

* \[x\] **ディレクトリ階層化**: data/raw, interim, processed の分離と管理。  
* \[x\] **統合CLI (sara\_cli.py)**: パイプラインの一元管理。  
* \[x\] **記憶の刈り込み (Synaptic Pruning)**: ノイズシナプスを削除し、メモリ効率と推論精度を向上。

## **フェーズ 2: 精度と一般化の向上 (Current)**

行列演算やGPUを使わず、SNN特有の性質でLLMに匹敵する「賢さ（汎化能力）」を実現する。

* \[ \] **曖昧さの許容 (Fuzzy Recall / SDR Overlap)**: 記憶と完全に一致しなくても、一定の類似度で連想を起動するアルゴリズムの実装。  
* \[ \] **階層的特徴抽出 (Hierarchical SDR)**:  
  * 視覚：エッジ（低次）→ 図形（中次）→ 物体（高次）  
  * 言語：文字（低次）→ 単語（中次）→ 文脈（高次）  
* \[ \] **予測符号化 (Predictive Coding)**: 教師なし学習による自動的なシナプス更新。  
* \[ \] **マルチソース統合**: PDF, Web, 画像等を一つの共通SNN空間で同時に学習する。

## **フェーズ 3: 商用デプロイ・エコシステム (Long-term)**

外部との接続と実社会での運用。

* \[ \] **CAPI / Rust SDK**: 他の言語（C++, Swift, Kotlin）からSARAを呼び出すためのインターフェース。  
* \[ \] **エッジ最適化**: Raspberry Pi やモバイル端末でのリアルタイム学習・推論の安定化。  
* \[ \] **監視ダッシュボード**: 記憶の密度や学習進捗をリアルタイムで可視化するWeb UI。

## **性能目標 (商用KPI)**

* **推論速度**: CPU単体で1トークンあたり10ms以内。  
* **メモリ効率**: 100万トークンの知識を 2GB 以内のRAMで保持。  
* **学習効率**: 誤差逆伝播法を用いた従来モデルの1/10以下のデータ量での特定ドメイン適応。