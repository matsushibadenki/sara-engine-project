{
    "//": "„Éá„Ç£„É¨„ÇØ„Éà„É™„Éë„Çπ: scripts/chat_rust_core.py",
    "//": "„Éï„Ç°„Ç§„É´„ÅÆÊó•Êú¨Ë™û„Çø„Ç§„Éà„É´: Rust„Ç≥„Ç¢Êê≠Ëºâ„ÉªË∂ÖÈ´òÈÄü„ÉÅ„É£„ÉÉ„Éà„Çπ„ÇØ„É™„Éó„ÉàÔºàSQLite & „Éë„ÇπÊúÄÈÅ©ÂåñÁâàÔºâ",
    "//": "„Éï„Ç°„Ç§„É´„ÅÆÁõÆÁöÑ„ÇÑÂÜÖÂÆπ: models/ ‰ª•‰∏ã„ÅÆMessagePack„É¢„Éá„É´„ÇíË™≠„ÅøËæº„Åø„ÄÅRust„Ç®„É≥„Ç∏„É≥„ÅßÊé®Ë´ñ„ÇíË°å„ÅÜ„ÄÇÈñæÂÄ§Âà∂Âæ°„Å´„Çà„ÇäÊú™Áü•„ÅÆË©±È°å„Å´„ÅØ„Äå„Çè„Åã„Çä„Åæ„Åõ„Çì„Äç„Å®ÂøúÁ≠î„Åô„ÇãÊ©üËÉΩ„ÇíÊê≠Ëºâ„ÄÇ"
}

import msgpack
import time
import os
from transformers import AutoTokenizer
from sara_engine.models.spiking_llm import SpikingLLM

try:
    from sara_engine import sara_rust_core
except ImportError:
    print("‚ùå sara_rust_core „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇRust„É¢„Ç∏„É•„Éº„É´„Çí„Éì„É´„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
    exit(1)

def run_rust_chat():
    # üí° „Éë„Çπ„ÅÆË®≠ÂÆöÔºà„É´„Éº„Éà„Åã„Çâ„ÅÆÁõ∏ÂØæ„Éë„ÇπÔºâ
    model_path = "models/distilled_sara_llm.msgpack"
    
    print("Loading tokenizer and initializing models...")
    tokenizer = AutoTokenizer.from_pretrained("google/gemma-2-2b")
    
    # SNN„ÅÆÂü∫Êú¨„Éë„É©„É°„Éº„ÇøÔºàËí∏ÁïôÊôÇ„Å®‰∏ÄËá¥„Åï„Åõ„ÇãÔºâ
    sdr_size = 8192 
    student = SpikingLLM(num_layers=2, sdr_size=sdr_size, vocab_size=256000)
    
    rust_engine = sara_rust_core.SpikeEngine()
    
    if not os.path.exists(model_path):
        print(f"‚ùå Error: '{model_path}' „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇÂÖà„Å´Ëí∏Áïô„ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
        return

    print(f"Loading distilled knowledge from {model_path} into Rust Core...")
    try:
        with open(model_path, "rb") as f:
            state = msgpack.unpack(f, raw=False)
            
        weights = [{} for _ in range(sdr_size)]
        pattern_count = 0
        
        # MessagePack„Åã„ÇâÈáç„Åø„ÇíÂ±ïÈñã
        for str_sdr_k, next_tokens in state["direct_map"].items():
            sdr_k = eval(str_sdr_k) 
            pattern_count += 1
            
            for str_tok_id, count in next_tokens.items():
                tok_id = int(str_tok_id)
                # „Çπ„Éë„Ç§„ÇØ„ÅÇ„Åü„Çä„ÅÆÈáç„Åø„ÇíË®àÁÆó
                weight_per_spike = float(count) / len(sdr_k) 
                
                for pre_id in sdr_k:
                    # Êó¢Â≠ò„ÅÆÈáç„Åø„Å®ÊúÄÂ§ßÂÄ§„ÇíÊØîËºÉ„Åó„Å¶‰øùÊåÅÔºà„Éè„Éñ„Éé„Éº„ÉâÊäëÂà∂Ôºâ
                    weights[pre_id][tok_id] = max(weights[pre_id].get(tok_id, 0.0), weight_per_spike)

        rust_engine.set_weights(weights)
        print(f"üöÄ Successfully transferred {pattern_count} patterns into Rust Core!")
        del state # „É°„É¢„É™Ëß£Êîæ
        
    except Exception as e:
        print(f"‚ùå Error during model loading: {e}")
        return

    print("\n" + "="*50)
    print("‚ö° SARA Rust Core Session Started (Multi-core Optimized)")
    print("ÁµÇ‰∫Ü„Åô„Çã„Å´„ÅØ 'quit' „Åæ„Åü„ÅØ 'exit' „Å®ÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
    print("="*50 + "\n")

    while True:
        try:
            user_input = input("You: ")
        except (KeyboardInterrupt, EOFError):
            print("\nExiting...")
            break

        if user_input.strip().lower() in ["quit", "exit"]:
            break
        if not user_input.strip():
            continue

        inputs = tokenizer(user_input, return_tensors="pt")
        current_tokens = inputs["input_ids"][0].tolist()

        print(f"SARA: ", end="", flush=True)
        
        start_time = time.time()
        generated_count = 0
        refractory_buffer = []

        # üí° Âé≥Ê†º„Å™Áô∫ÁÅ´ÈñæÂÄ§ÔºàË™§Áô∫ÁÅ´Èò≤Ê≠¢Ôºâ
        fire_threshold = 60.0 

        for step in range(30):
            # Áõ¥Ëøë8„Éà„Éº„ÇØ„É≥„ÅÆÊñáËÑà„Çí‰ΩøÁî®
            context_tokens = current_tokens[-8:]
            sdr = student._encode_to_sdr(context_tokens)
            
            # Rust„Ç≥„Ç¢„Åß„Çπ„Éë„Ç§„ÇØ‰ºùÊí≠
            out_spikes = rust_engine.propagate(sdr, fire_threshold, 10)
            
            # ÈñæÂÄ§„ÇíË∂Ö„Åà„ÇãÂÄôË£ú„Åå„Å™„ÅÑÂ†¥Âêà
            if not out_spikes:
                if step == 0:
                    print("„Åô„Åø„Åæ„Åõ„Çì„ÄÅ„Åù„ÅÆË©±È°å„Å´„Å§„ÅÑ„Å¶„ÅØ„Åæ„Å†Â≠¶Áøí„Åó„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ", end="")
                break
                
            # ‰∏çÂøúÊúüÔºàRefractory PeriodÔºâ„ÉÅ„Çß„ÉÉ„ÇØ: Áõ¥Ëøë3ÂçòË™û„ÅÆ„É´„Éº„Éó„ÇíÈò≤Ê≠¢
            next_id = None
            for candidate in out_spikes:
                if candidate not in refractory_buffer:
                    next_id = candidate
                    break
            
            # ÂÄôË£ú„Åå„Åô„Åπ„Å¶‰∏çÂøúÊúü„Å™„Çâ„Éà„ÉÉ„Éó„ÇíÊé°Áî®
            if next_id is None:
                next_id = out_spikes[0]
                
            current_tokens.append(next_id)
            generated_word = tokenizer.decode([next_id])
            generated_count += 1
            
            print(generated_word, end="", flush=True)
            
            # ‰∏çÂøúÊúü„Éê„ÉÉ„Éï„Ç°„ÅÆÊõ¥Êñ∞
            refractory_buffer.append(next_id)
            if len(refractory_buffer) > 3:
                refractory_buffer.pop(0)
            
            # ÁµÇÁ´ØË®òÂè∑„ÅßÁîüÊàê„ÇíÁµÇ‰∫Ü
            if generated_word.strip() in ["„ÄÇ", "ÔºÅ", "Ôºü", "!", "?", "\n"]:
                break
                
        elapsed_time = time.time() - start_time
        tps = generated_count / elapsed_time if elapsed_time > 0 else 0
        
        if generated_count > 0:
            print(f"\n      [‚è±Ô∏è Speed: {tps:.2f} tokens/sec]")
        else:
            print()

if __name__ == "__main__":
    run_rust_chat()