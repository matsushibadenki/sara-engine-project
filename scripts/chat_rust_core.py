# „Éá„Ç£„É¨„ÇØ„Éà„É™„Éë„Çπ: scripts/chat_rust_core.py
# „Éï„Ç°„Ç§„É´„ÅÆÊó•Êú¨Ë™û„Çø„Ç§„Éà„É´: Rust„Ç≥„Ç¢Êê≠Ëºâ„ÉªË∂ÖÈ´òÈÄü„ÉÅ„É£„ÉÉ„Éà„Çπ„ÇØ„É™„Éó„ÉàÔºàÊú™Áü•Ë™û„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÂØæÂøúÁâàÔºâ
# „Éï„Ç°„Ç§„É´„ÅÆÁõÆÁöÑ„ÇÑÂÜÖÂÆπ: SNN„ÅÆÁ¢∫‰ø°Â∫¶ÔºàÁô∫ÁÅ´ÈñæÂÄ§Ôºâ„ÇíÂà©Áî®„Åó„ÄÅÊú™Áü•„ÅÆÊñáËÑà„ÅåÂÖ•Âäõ„Åï„Çå„ÅüÈöõ„Å´„Éé„Ç§„Ç∫„ÇíÂá∫Âäõ„Åô„Çã„ÅÆ„Åß„ÅØ„Å™„Åè„Äå„Çè„Åã„Çä„Åæ„Åõ„Çì„Äç„Å®Ëøî„ÅôÊ©üËÉΩ„ÇíÂÆüË£Ö„ÄÇ

FILE_INFO = {
    "//": "„Ç≥„É°„É≥„Éà: ÈñæÂÄ§Âà∂Âæ°„Å´„Çà„Çä„Éè„É´„Ç∑„Éç„Éº„Ç∑„Éß„É≥ÔºàÁü•„Å£„Åü„Åã„Å∂„ÇäÔºâ„ÇíÈò≤Ê≠¢„Åó„Åæ„Åô„ÄÇ"
}

import json
import time
from transformers import AutoTokenizer
from sara_engine.models.spiking_llm import SpikingLLM

try:
    from sara_engine import sara_rust_core
except ImportError:
    print("‚ùå sara_rust_core „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")
    exit(1)

def run_rust_chat():
    print("Loading tokenizer and initializing models...")
    tokenizer = AutoTokenizer.from_pretrained("google/gemma-2-2b")
    
    sdr_size = 8192 
    student = SpikingLLM(num_layers=2, sdr_size=sdr_size, vocab_size=256000)
    
    rust_engine = sara_rust_core.SpikeEngine()
    
    print("Loading distilled knowledge into Rust Core...")
    try:
        # Êã°ÂºµÂ≠ê„Ååmsgpack„ÅÆÂ†¥Âêà„ÅØ msgpack „É¢„Ç∏„É•„Éº„É´„ÅåÂøÖË¶Å„Åß„Åô„Åå„ÄÅ
        # Áõ¥Ëøë„ÅÆ„ÉÜ„Çπ„Éà„Å´Âêà„Çè„Åõ„Å¶MessagePack„Åã„Çâ„ÅÆË™≠„ÅøËæº„ÅøÂá¶ÁêÜ„ÇíÁµÑ„ÅøËæº„Åø„Åæ„Åô„ÄÇ
        import msgpack
        import os
        model_path = "distilled_sara_llm.msgpack"
        
        if not os.path.exists(model_path):
            print(f"‚ùå Error: '{model_path}' „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")
            return
            
        with open(model_path, "rb") as f:
            state = msgpack.unpack(f, raw=False)
            
        weights = [{} for _ in range(sdr_size)]
        pattern_count = 0
        
        for str_sdr_k, next_tokens in state["direct_map"].items():
            sdr_k = eval(str_sdr_k) 
            pattern_count += 1
            
            for str_tok_id, count in next_tokens.items():
                tok_id = int(str_tok_id)
                weight_per_spike = float(count) / len(sdr_k) 
                
                for pre_id in sdr_k:
                    if tok_id not in weights[pre_id]:
                        weights[pre_id][tok_id] = 0.0
                    
                    weights[pre_id][tok_id] = max(weights[pre_id][tok_id], weight_per_spike)

        rust_engine.set_weights(weights)
        print(f"üöÄ Successfully transferred {pattern_count} patterns into Rust Core!")
        
    except Exception as e:
        print(f"‚ùå Error loading model: {e}")
        return

    print("\n" + "="*50)
    print("‚ö° SARA Rust Core Session Started (MessagePack & Fallback Optimized)")
    print("ÁµÇ‰∫Ü„Åô„Çã„Å´„ÅØ 'quit' „Åæ„Åü„ÅØ 'exit' „Å®ÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
    print("="*50 + "\n")

    while True:
        try:
            user_input = input("You: ")
        except (KeyboardInterrupt, EOFError):
            break

        if user_input.strip().lower() in ["quit", "exit"]:
            break
        if not user_input.strip():
            continue

        inputs = tokenizer(user_input, return_tensors="pt")
        current_tokens = inputs["input_ids"][0].tolist()

        print(f"SARA: ", end="", flush=True)
        
        start_time = time.time()
        generated_count = 0
        refractory_buffer = []

        # üí° Áô∫ÁÅ´ÈñæÂÄ§„ÅÆË®≠ÂÆöÔºà„Åì„ÅÆÊï∞ÂÄ§‰ª•‰∏ã„ÅÆÁ¢∫‰ø°Â∫¶„ÅÆÂçòË™û„ÅØÁÑ°Ë¶ñ„Åô„ÇãÔºâ
        # Teacher Forcing „Åß 100.0 „Å™„Å©„ÅÆÈáç„Åø„Çí„Å§„Åë„Å¶„ÅÑ„Çã„Åü„ÇÅ„ÄÅ
        # ÂÆåÂÖ®„Å´Êú™Áü•„ÅÆÊñáËÑà„Å†„Å®ÂêàË®àÂÄ§„Åå„Åì„Çå„Çí‰∏ãÂõû„Çä„Åæ„Åô„ÄÇÁí∞Â¢É„Å´Âêà„Çè„Åõ„Å¶Ë™øÊï¥ÂèØËÉΩ„Åß„Åô„ÄÇ
        fire_threshold = 2.0 

        for step in range(30):
            context_tokens = current_tokens[-8:]
            sdr = student._encode_to_sdr(context_tokens)
            
            # üí° ÈñæÂÄ§„ÇíË®≠ÂÆö„Åó„Å¶Rust„Ç≥„Ç¢„ÇíÂëº„Å≥Âá∫„Åó
            out_spikes = rust_engine.propagate(sdr, fire_threshold, 10)
            
            # üí° ÈñæÂÄ§„ÇíË∂Ö„Åà„ÇãÂçòË™û„Åå1„Å§„ÇÇË¶ã„Å§„Åã„Çâ„Å™„Åã„Å£„ÅüÂ†¥Âêà„ÅÆÂá¶ÁêÜ
            if not out_spikes:
                if step == 0:
                    # 1ÊñáÂ≠ó„ÇÇÁîüÊàê„Åß„Åç„Åö„Å´ÁµÇ„Çè„Å£„ÅüÔºùÂÆåÂÖ®„Å´Áü•„Çâ„Å™„ÅÑË©±È°å
                    print("„Åô„Åø„Åæ„Åõ„Çì„ÄÅ„Åù„ÅÆË©±È°å„Å´„Å§„ÅÑ„Å¶„ÅØ„Åæ„Å†Â≠¶Áøí„Åó„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇ", end="")
                break
                
            next_id = None
            for candidate in out_spikes:
                if candidate not in refractory_buffer:
                    next_id = candidate
                    break
            
            if next_id is None:
                next_id = out_spikes[0]
                
            current_tokens.append(next_id)
            generated_word = tokenizer.decode([next_id])
            generated_count += 1
            
            print(generated_word, end="", flush=True)
            
            refractory_buffer.append(next_id)
            if len(refractory_buffer) > 3:
                refractory_buffer.pop(0)
            
            if generated_word.strip() in ["„ÄÇ", "ÔºÅ", "Ôºü", "!", "?", "\n"]:
                break
                
        elapsed_time = time.time() - start_time
        tps = generated_count / elapsed_time if elapsed_time > 0 else 0
        
        print(f"\n      [‚è±Ô∏è Speed: {tps:.2f} tokens/sec]")

if __name__ == "__main__":
    run_rust_chat()