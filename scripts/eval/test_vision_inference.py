# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹: scripts/eval/test_vision_inference.py
# ãƒ•ã‚¡ã‚¤ãƒ«ã®æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«: è¦–è¦šé€£æƒ³æ¨è«–ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# ãƒ•ã‚¡ã‚¤ãƒ«ã®ç›®çš„ã‚„å†…å®¹: å­¦ç¿’æ¸ˆã¿ã®SNNãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€å…¥åŠ›ç”»åƒã‹ã‚‰é–¢é€£ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆï¼ˆã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã‚’é€£æƒ³ãƒ»å¾©å…ƒã§ãã‚‹ã‹ç¢ºèªã™ã‚‹ã€‚

import os
import msgpack
import numpy as np
from PIL import Image
from sara_engine.models.spiking_llm import SpikingLLM
from sara_engine.encoders.vision import ImageSpikeEncoder
from transformers import AutoTokenizer

def run_vision_inference(image_path, model_path):
    """
    ç”»åƒã‚’å…¥åŠ›ã—ã€SNNã®ç›´æ¥è¨˜æ†¶ãƒãƒƒãƒ—ã‹ã‚‰é€£æƒ³ã•ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡ºåŠ›ã™ã‚‹ã€‚
    """
    if not os.path.exists(model_path):
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
        return
    if not os.path.exists(image_path):
        print(f"âŒ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
        return

    print(f"--- è¦–è¦šé€£æƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­: {image_path} ---")
    
    # 1. ãƒ¢ãƒ‡ãƒ«ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®åˆæœŸåŒ–ï¼ˆå­¦ç¿’æ™‚ã¨åŒã˜è¨­å®šï¼‰
    student = SpikingLLM(num_layers=2, sdr_size=8192, vocab_size=256000)
    vision_encoder = ImageSpikeEncoder(output_size=8192)
    tokenizer = AutoTokenizer.from_pretrained("google/gemma-2-2b")

    # 2. ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    with open(model_path, "rb") as f:
        state = msgpack.unpack(f, raw=False)
    
    raw_map = state.get("direct_map", {})
    # ã‚­ãƒ¼ã‚’å¾©å…ƒ
    student._direct_map = {eval(k): {int(tk): float(tv) for tk, tv in v.items()} for k, v in raw_map.items()}
    print(f"âœ… {len(student._direct_map)} ä»¶ã®è¨˜æ†¶ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")

    # 3. å…¥åŠ›ç”»åƒã®SDRåŒ–
    try:
        # å­¦ç¿’æ™‚ã¨åŒã˜å‰å‡¦ç† (64x64, ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«, 0.0-1.0)
        image = Image.open(image_path).convert('L').resize((64, 64))
        pixel_values = list(np.array(image).flatten() / 255.0)
        
        vision_sdr = vision_encoder.encode(pixel_values)
        vision_key = student._sdr_key(vision_sdr)

        # 4. é€£æƒ³è¨˜æ†¶ã®å¼•ãå‡ºã—
        print("\nSARAã®é€£æƒ³çµæœ:")
        if vision_key in student._direct_map:
            # é‡ã¿ã®é«˜ã„é †ã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—
            token_weights = student._direct_map[vision_key]
            # ä¸Šä½ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
            sorted_tokens = sorted(token_weights.items(), key=lambda x: x[1], reverse=True)
            
            # ãƒˆãƒ¼ã‚¯ãƒ³IDã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            token_ids = [t[0] for t in sorted_tokens]
            
            # ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¦è¡¨ç¤º
            decoded_text = tokenizer.decode(token_ids)
            print(f"âœ¨ èªè­˜å†…å®¹: {decoded_text}")
            
            # è©³ç´°ï¼ˆé‡ã¿ä»˜ãï¼‰
            print("\n[å†…éƒ¨ç™ºç«å¼·åº¦]")
            for tid, weight in sorted_tokens[:5]:
                print(f" - '{tokenizer.decode([tid])}': {weight:.2f}")
        else:
            print("ğŸ¤” ãã®ç”»åƒãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾ã™ã‚‹è¨˜æ†¶ï¼ˆé€£æƒ³çµåˆï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            print("ï¼ˆå­¦ç¿’ã—ãŸç”»åƒã¨ç‰¹å¾´ãŒå¤§ããç•°ãªã‚‹ã‹ã€ç‰¹å¾´æŠ½å‡ºã®é–¾å€¤ã‚’è¶…ãˆã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰")
            
    except Exception as e:
        print(f"âŒ æ¨è«–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    # ç›´æ¥å®Ÿè¡Œç”¨
    run_vision_inference("data/raw/visual/images/apple.jpg", "models/distilled_sara_llm.msgpack")