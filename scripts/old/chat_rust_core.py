# [ÈÖçÁΩÆ„Åô„Çã„Éá„Ç£„É¨„ÇØ„Éà„É™„ÅÆ„Éë„Çπ]: ./scripts/old/chat_rust_core.py
# [„Éï„Ç°„Ç§„É´„ÅÆÊó•Êú¨Ë™û„Çø„Ç§„Éà„É´]: Rust„Ç≥„Ç¢Êé®Ë´ñ„Çπ„ÇØ„É™„Éó„Éà („ÇΩ„Éï„Éà„Éª„Éö„Éä„É´„ÉÜ„Ç£‰øÆÊ≠£Áâà)
# [„Éï„Ç°„Ç§„É´„ÅÆÁõÆÁöÑ„ÇÑÂÜÖÂÆπ]: 8192„Éã„É•„Éº„É≠„É≥„ÅÆ„Åæ„Åæ„ÄÅÂä©Ë©û„ÅÆ„Éè„ÉñÂåñ„ÅÆ„Åø„ÇíÂÆâÂÖ®„Å™ÂØæÊï∞„Éö„Éä„É´„ÉÜ„Ç£„ÅßÊäëÂà∂„Åó„ÄÅ„ÉØ„Éº„Éâ„Çµ„É©„ÉÄ„ÇíÂÆåÂÖ®„Å´Èò≤„Åê„ÄÇ
{
    "//": "„Éá„Ç£„É¨„ÇØ„Éà„É™„Éë„Çπ: scripts/chat_rust_core.py",
    "//": "„Éï„Ç°„Ç§„É´„ÅÆÊó•Êú¨Ë™û„Çø„Ç§„Éà„É´: Rust„Ç≥„Ç¢Êé®Ë´ñ„Çπ„ÇØ„É™„Éó„Éà („ÇΩ„Éï„Éà„Éª„Éö„Éä„É´„ÉÜ„Ç£‰øÆÊ≠£Áâà)",
    "//": "„Éï„Ç°„Ç§„É´„ÅÆÁõÆÁöÑ„ÇÑÂÜÖÂÆπ: 8192„Éã„É•„Éº„É≠„É≥„ÅÆ„Åæ„Åæ„ÄÅÂä©Ë©û„ÅÆ„Éè„ÉñÂåñ„ÅÆ„Åø„ÇíÂÆâÂÖ®„Å™ÂØæÊï∞„Éö„Éä„É´„ÉÜ„Ç£„ÅßÊäëÂà∂„Åó„ÄÅ„ÉØ„Éº„Éâ„Çµ„É©„ÉÄ„ÇíÂÆåÂÖ®„Å´Èò≤„Åê„ÄÇ"
}

import msgpack
import time
import os
import math
import tqdm
from transformers import AutoTokenizer
from sara_engine.models.spiking_llm import SpikingLLM

try:
    from sara_engine import sara_rust_core # type: ignore
except ImportError:
    print("‚ùå sara_rust_core „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")
    exit(1)

def run_rust_chat():
    model_path = "models/distilled_sara_llm.msgpack"
    tokenizer = AutoTokenizer.from_pretrained("google/gemma-2-2b")
    sdr_size = 8192 
    student = SpikingLLM(num_layers=2, sdr_size=sdr_size, vocab_size=256000)
    rust_engine = sara_rust_core.SpikeEngine()
    
    if not os.path.exists(model_path):
        print(f"‚ùå Error: '{model_path}' „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")
        return

    print(f"Loading distilled knowledge from {model_path}...")
    with open(model_path, "rb") as f:
        state = msgpack.unpack(f, raw=False)
    
    items = list(state.get("direct_map", {}).items())
    
    print("Analyzing neural pathways (Applying Safe Soft-Penalty)...")
    token_freq: dict[int, int] = {}
    for str_sdr_k, next_tokens in items:
        for str_tok_id, count in next_tokens.items():
            tok_id = int(str_tok_id)
            token_freq[tok_id] = token_freq.get(tok_id, 0) + 1

    weights: list[dict[int, float]] = [{} for _ in range(sdr_size)]
    
    for str_sdr_k, next_tokens in tqdm.tqdm(items, desc="Transferring to Rust Core"):
        sdr_k = eval(str_sdr_k)
        for str_tok_id, count in next_tokens.items():
            tok_id = int(str_tok_id)
            freq = token_freq.get(tok_id, 1)
            
            # üí° ‰øÆÊ≠£ÁÇπÔºöÂ∏åÂ∞ë„Å™Ë®ÄËëâ„ÇíÁàÜÁô∫„Åï„Åõ„Åö„ÄÅ10Âõû‰ª•‰∏äÂá∫Áèæ„Åó„ÅüË®ÄËëâ„ÅÆ„Åø„ÇíÂØæÊï∞„ÅßÂÑ™„Åó„ÅèÊäëÂà∂
            penalty = 1.0
            if freq > 10:
                penalty = 1.0 / math.log10(freq)
            
            weight_per_spike = (float(count) / len(sdr_k)) * penalty
            
            for pre_id in sdr_k:
                weights[pre_id][tok_id] = max(weights[pre_id].get(tok_id, 0.0), weight_per_spike)

    rust_engine.set_weights(weights)
    print(f"üöÄ Successfully transferred {len(items)} patterns into Rust Core!")
    del state

    print("\n" + "="*50)
    print("‚ö° SARA Rust Core Session (Safe Hub-Suppression)")
    print("ÁµÇ‰∫Ü„Åô„Çã„Å´„ÅØ 'quit' „Åæ„Åü„ÅØ 'exit' „Å®ÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
    print("="*50 + "\n")

    while True:
        try:
            user_input = input("\nYou: ")
        except (KeyboardInterrupt, EOFError): break
        if user_input.strip().lower() in ["quit", "exit"]: break
        if not user_input.strip(): continue

        inputs = tokenizer(user_input, return_tensors="pt")
        current_tokens = inputs["input_ids"][0].tolist()

        print(f"SARA: ", end="", flush=True)
        start_time = time.time()
        generated_count = 0
        refractory_buffer = []

        # üí° „Çπ„Éë„Ç§„ÇØ„ÅåÊ≠£Â∏∏Âåñ„Åï„Çå„Åü„Åü„ÇÅ„ÄÅÈÅ©Âàá„Å™ÈñæÂÄ§„ÇíË®≠ÂÆö
        fire_threshold = 40.0 

        for step in range(50): 
            context_tokens = current_tokens[-8:]
            sdr = student._encode_to_sdr(context_tokens)
            
            # ÂÄôË£ú„Çí5„Å§ÂèñÂæó
            out_spikes = rust_engine.propagate(sdr, fire_threshold, 5)
            
            if not out_spikes:
                if step == 0:
                    print("Ôºà„Åæ„Å†Â≠¶Áøí„Åó„Å¶„ÅÑ„Å™„ÅÑË®ÄËëâ„ÅÆÁπã„Åå„Çä„Åß„ÅôÔºâ", end="")
                break
                
            next_id = None
            for candidate in out_spikes:
                if candidate not in refractory_buffer:
                    next_id = candidate
                    break
            
            if next_id is None:
                next_id = out_spikes[0]
                
            current_tokens.append(next_id)
            generated_word = tokenizer.decode([next_id])
            generated_count += 1
            print(generated_word, end="", flush=True)
            
            refractory_buffer.append(next_id)
            if len(refractory_buffer) > 4:
                refractory_buffer.pop(0)
            
            if generated_word.strip() in ["„ÄÇ", "ÔºÅ", "Ôºü", "!", "?", "\n"]:
                break
                
        elapsed_time = time.time() - start_time
        tps = generated_count / elapsed_time if elapsed_time > 0 else 0
        if generated_count > 0:
            print(f"\n      [‚è±Ô∏è Speed: {tps:.2f} tokens/sec]")

if __name__ == "__main__":
    run_rust_chat()