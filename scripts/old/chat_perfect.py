{
    "//": "„Éá„Ç£„É¨„ÇØ„Éà„É™„Éë„Çπ: scripts/chat_perfect.py",
    "//": "„Éï„Ç°„Ç§„É´„ÅÆÊó•Êú¨Ë™û„Çø„Ç§„Éà„É´: SARAÊµ∑È¶¨Êé®Ë´ñ„Çπ„ÇØ„É™„Éó„ÉàÔºàBPEÂÆåÂÖ®Á™ÅÁ†¥ÁâàÔºâ",
    "//": "„Éï„Ç°„Ç§„É´„ÅÆÁõÆÁöÑ„ÇÑÂÜÖÂÆπ: ÊñáÂ≠óÂàó„É¨„Éô„É´„Åß„ÅÆÈùíÁ©∫ÊñáÂ∫´Ë£úÊ≠£„Å®„ÄÅBPE„ÅÆÂàÜÊñ≠„ÇíÈò≤„Åê„ÄåÊú´Â∞æ„Éà„Éº„ÇØ„É≥Âàá„ÇäÊç®„Å¶Ê§úÁ¥¢„Äç„ÇíÂÆüË£Ö„Åó„ÄÅ„ÅÇ„Çâ„ÇÜ„ÇãÂÖ•Âäõ„Åã„ÇâË®òÊÜ∂„ÇíÂºï„ÅçÂá∫„Åô„ÄÇ"
}

import msgpack
import time
import os
import numpy as np
from transformers import AutoTokenizer
from sara_engine.models.spiking_llm import SpikingLLM

def run_perfect_chat():
    model_path = "models/distilled_sara_llm.msgpack"
    tokenizer = AutoTokenizer.from_pretrained("google/gemma-2-2b")
    student = SpikingLLM(num_layers=2, sdr_size=8192, vocab_size=256000)
    
    if not os.path.exists(model_path):
        print(f"‚ùå '{model_path}' „ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ")
        return

    print("Loading Perfect Memory (Hippocampus Engine)...")
    with open(model_path, "rb") as f:
        state = msgpack.unpack(f, raw=False)
    
    direct_map = state.get("direct_map", {})
    print(f"üöÄ Successfully loaded {len(direct_map)} pure memories!")

    print("\n" + "="*50)
    print("‚ö° SARA Hippocampus Session (BPE-Resilient Mode)")
    print("ÁµÇ‰∫Ü„Åô„Çã„Å´„ÅØ 'quit' „Åæ„Åü„ÅØ 'exit' „Å®ÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
    print("="*50 + "\n")

    while True:
        try:
            user_input = input("\nYou: ")
        except (KeyboardInterrupt, EOFError): break
        if user_input.strip().lower() in ["quit", "exit"]: break
        if not user_input.strip(): continue

        # üí° ÊñáÂ≠óÂàó„É¨„Éô„É´„Åß„ÅÆÊ§úÁ¥¢„Éê„É™„Ç®„Éº„Ç∑„Éß„É≥Ôºà„Åì„Åì„ÅßÂàù„ÇÅ„Å¶„Éà„Éº„ÇØ„É≥Âåñ„Åô„ÇãÔºâ
        string_variations = [
            user_input,                 # „Åù„ÅÆ„Åæ„Åæ
            "„ÄÄ" + user_input,           # ÈùíÁ©∫ÊñáÂ∫´„ÅÆÊÆµËêΩÈñãÂßãÔºàÂÖ®Ëßí„Çπ„Éö„Éº„ÇπÔºâ
            "„Äå" + user_input            # ‰ºöË©±ÊñáÈñãÂßã
        ]

        print(f"SARA: ", end="", flush=True)
        start_time = time.time()
        generated_count = 0
        refractory_buffer = []

        # ÁèæÂú®„ÅÆ„Éà„Éº„ÇØ„É≥ÂàóÔºàÂàùÊúüÁä∂ÊÖã„ÅØNone„ÄÅÊ§úÁ¥¢ÊàêÂäüÊôÇ„Å´„Çª„ÉÉ„Éà„Åï„Çå„ÇãÔºâ
        current_tokens = []
        next_id = None

        # üí° Step 1: ÊúÄÂàù„ÅÆ‰∏ÄË®ÄÁõÆ„ÇíË¶ã„Å§„Åë„Çã„Åü„ÇÅ„ÅÆÂº∑Âäõ„Å™Ê§úÁ¥¢
        for text_var in string_variations:
            base_tokens = tokenizer(text_var, return_tensors="pt")["input_ids"][0].tolist()
            
            # BPE„ÅÆÂàÜÊñ≠ÂØæÁ≠ñÔºö„Äå„Åù„ÅÆ„Åæ„Åæ„Äç„Å®„ÄåÊúÄÂæå„ÅÆ1„Éà„Éº„ÇØ„É≥„ÇíÂâä„Å£„ÅüÁä∂ÊÖã„Äç„ÅÆ‰∏°Êñπ„ÇíË©¶„Åô
            for drop_last in [False, True]:
                search_tokens = base_tokens[:-1] if drop_last and len(base_tokens) > 2 else base_tokens
                if not search_tokens: continue

                max_window = min(8, len(search_tokens))
                for window in range(max_window, 0, -1):
                    context = search_tokens[-window:]
                    sdr_k = str(student._sdr_key(student._encode_to_sdr(context)))
                    
                    if sdr_k in direct_map:
                        valid_candidates = [
                            (int(cid), w) for cid, w in direct_map[sdr_k].items() 
                        ]
                        
                        if valid_candidates:
                            top_k = min(3, len(valid_candidates))
                            valid_candidates.sort(key=lambda x: x[1], reverse=True)
                            top_candidates = valid_candidates[:top_k]
                            
                            weights = np.array([w for _, w in top_candidates])
                            probs = weights ** 2
                            probs /= probs.sum()
                            
                            chosen_index = np.random.choice(len(top_candidates), p=probs)
                            next_id = top_candidates[chosen_index][0]
                            
                            # Ê§úÁ¥¢ÊàêÂäüÔºÅ„Éô„Éº„Çπ„Éà„Éº„ÇØ„É≥„ÇíÊõ¥Êñ∞
                            current_tokens = search_tokens
                            break
                if next_id is not None: break
            if next_id is not None: break

        # ÊúÄÂàù„ÅÆ‰∏ÄË®Ä„ÅåË¶ã„Å§„Åã„Çâ„Å™„Åã„Å£„ÅüÂ†¥Âêà
        if next_id is None:
            print("Ôºà„Åù„ÅÆË®ÄËëâ„ÅÆÁ∂ö„Åç„ÅØ„ÄÅ„Åæ„Å†Êº±Áü≥„ÅÆË®òÊÜ∂„Å´„ÅÇ„Çä„Åæ„Åõ„ÇìÔºâ", flush=True)
            continue

        # üí° Step 2: Ë¶ã„Å§„Åã„Å£„ÅüÊñáËÑà„Åã„ÇâË®ÄËëâ„ÇíÁ¥°„ÅéÁ∂ö„Åë„Çã„É´„Éº„Éó
        for step in range(60): 
            if step > 0: # 2ÂçòË™ûÁõÆ‰ª•Èôç„ÅÆÊ§úÁ¥¢
                next_id = None
                max_window = min(8, len(current_tokens))
                for window in range(max_window, 0, -1):
                    context = current_tokens[-window:]
                    sdr_k = str(student._sdr_key(student._encode_to_sdr(context)))
                    
                    if sdr_k in direct_map:
                        valid_candidates = [
                            (int(cid), w) for cid, w in direct_map[sdr_k].items() 
                            if int(cid) not in refractory_buffer
                        ]
                        if valid_candidates:
                            top_k = min(3, len(valid_candidates))
                            valid_candidates.sort(key=lambda x: x[1], reverse=True)
                            top_candidates = valid_candidates[:top_k]
                            
                            weights = np.array([w for _, w in top_candidates])
                            probs = weights ** 2
                            probs /= probs.sum()
                            
                            chosen_index = np.random.choice(len(top_candidates), p=probs)
                            next_id = top_candidates[chosen_index][0]
                            break 
                
                if next_id is None:
                    break
            
            # „Éà„Éº„ÇØ„É≥„ÅÆËøΩÂä†„Å®Âá∫Âäõ
            current_tokens.append(next_id)
            generated_word = tokenizer.decode([next_id])
            generated_count += 1
            
            print(generated_word, end="", flush=True)
            
            # Áõ¥Ëøë3ÂçòË™û„ÅÆ‰∏çÂøúÊúü„É´„Éº„ÉóÈò≤Ê≠¢
            refractory_buffer.append(next_id)
            if len(refractory_buffer) > 3:
                refractory_buffer.pop(0)
            
            # ÁµÇ‰∫ÜÂà§ÂÆö
            if generated_word.strip() in ["„ÄÇ", "ÔºÅ", "Ôºü", "!", "?", "\n"]:
                break
                
        elapsed_time = time.time() - start_time
        tps = generated_count / elapsed_time if elapsed_time > 0 else 0
        if generated_count > 0:
            print(f"\n      [‚è±Ô∏è Speed: {tps:.2f} tokens/sec]")

if __name__ == "__main__":
    run_perfect_chat()